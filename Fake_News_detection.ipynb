{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAkHbgijQJ6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca4e94b-eee3-498b-9efa-9a7e45b983e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "P9XFtpgWQWk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79a4815-5d4c-423e-e5a2-f1d8968f75d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/fake-and-real-news-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df = pd.read_csv((path + \"/Fake.csv\"))\n",
        "true_df = pd.read_csv((path + \"/True.csv\"))\n",
        "fake_df['label'] = 0\n",
        "true_df['label'] = 1"
      ],
      "metadata": {
        "id": "HgzZ2lp0Q_i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([fake_df, true_df], axis=0).reset_index(drop=True)\n",
        "print(\"Datasets loaded and combined successfully!\")\n",
        "print(\"First 5 rows of the combined data:\")\n",
        "print(df.head())\n",
        "print(\"\\nLast 5 rows of the combined data:\")\n",
        "print(df.tail())"
      ],
      "metadata": {
        "id": "Kjlp3rGDUcpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cb59e6-1b0b-4a4c-c49a-7e18136ee9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets loaded and combined successfully!\n",
            "First 5 rows of the combined data:\n",
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Yearâ€™...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
            "3   Trump Is So Obsessed He Even Has Obamaâ€™s Name...   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...    News   \n",
            "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
            "2  On Friday, it was revealed that former Milwauk...    News   \n",
            "3  On Christmas day, Donald Trump announced that ...    News   \n",
            "4  Pope Francis used his annual Christmas Day mes...    News   \n",
            "\n",
            "                date  label  \n",
            "0  December 31, 2017      0  \n",
            "1  December 31, 2017      0  \n",
            "2  December 30, 2017      0  \n",
            "3  December 29, 2017      0  \n",
            "4  December 25, 2017      0  \n",
            "\n",
            "Last 5 rows of the combined data:\n",
            "                                                   title  \\\n",
            "44893  'Fully committed' NATO backs new U.S. approach...   \n",
            "44894  LexisNexis withdrew two products from Chinese ...   \n",
            "44895  Minsk cultural hub becomes haven from authorities   \n",
            "44896  Vatican upbeat on possibility of Pope Francis ...   \n",
            "44897  Indonesia to buy $1.14 billion worth of Russia...   \n",
            "\n",
            "                                                    text    subject  \\\n",
            "44893  BRUSSELS (Reuters) - NATO allies on Tuesday we...  worldnews   \n",
            "44894  LONDON (Reuters) - LexisNexis, a provider of l...  worldnews   \n",
            "44895  MINSK (Reuters) - In the shadow of disused Sov...  worldnews   \n",
            "44896  MOSCOW (Reuters) - Vatican Secretary of State ...  worldnews   \n",
            "44897  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...  worldnews   \n",
            "\n",
            "                   date  label  \n",
            "44893  August 22, 2017       1  \n",
            "44894  August 22, 2017       1  \n",
            "44895  August 22, 2017       1  \n",
            "44896  August 22, 2017       1  \n",
            "44897  August 22, 2017       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "df['cleaned'] = df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "y2BLdb22VLQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X = df['cleaned']\n",
        "y = df['label']\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "print(\"Shape of the vectorized data (X_vec):\", X_vec.shape)"
      ],
      "metadata": {
        "id": "Xg3NZtk53sL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3dd403-6f44-4c87-cd38-7bc4ee85ba2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the vectorized data (X_vec): (44898, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_vec, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "gXoWg8C0J7zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6a5487-1188-4154-e678-1b0b487dda80"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (35918, 5000)\n",
            "Shape of X_test: (8980, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete!\")"
      ],
      "metadata": {
        "id": "xUVkhq5GNHsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9243c92e-5723-4079-9986-3a42adae2124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred  = model.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Fake (0)', 'Real (1)']))"
      ],
      "metadata": {
        "id": "VrUxF8dLVXK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c123fbe-886f-4c76-988d-a0c5a62e16fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 98.70%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Fake (0)       0.99      0.99      0.99      4733\n",
            "    Real (1)       0.98      0.99      0.99      4247\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# general testing\n",
        "news = \"NASA gets cancelled by USA\"\n",
        "clean_text = preprocess(news)\n",
        "vec_text = vectorizer.transform([clean_text])\n",
        "prediction = model.predict(vec_text)\n",
        "print(\"Prediction:\", prediction)\n",
        "\n",
        "if prediction ==0 :\n",
        "  print(\"Fake News\")\n",
        "else:\n",
        "  print(\"Real News\")"
      ],
      "metadata": {
        "id": "n0QxEqGTW4Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12b4534-5c3e-46e9-d466-48c76a3d9eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [0]\n",
            "Fake News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def predict_news(text):\n",
        "    cleaned = preprocess(text)\n",
        "    vectorized = vectorizer.transform([cleaned])\n",
        "    pred = model.predict(vectorized)[0]\n",
        "    return 'Real News' if pred == 1 else 'Fake News'\n",
        "\n",
        "# Creating the Gradio Interface\n",
        "print(\"\\nLaunching the Gradio demo app...\")\n",
        "demo = gr.Interface(fn=predict_news,\n",
        "                    inputs='text',\n",
        "                    outputs='text',\n",
        "                    title='ðŸ“° Fake News Detector',\n",
        "                    description='Paste a news headline or article and check if it\\'s real or fake.')\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "ZGLOLODGZC1O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "f2f74f87-44e5-4245-c4f5-d1dc0cc244b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Launching the Gradio demo app...\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://18b69bcb092a554510.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://18b69bcb092a554510.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWB0_z3ec5tg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}